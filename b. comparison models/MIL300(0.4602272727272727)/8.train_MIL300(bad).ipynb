{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from main_new_MIL300 import train\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'news_set/vocab_cased_title.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bbed578e2648>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mdictionary\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0;34m'news_set/vocab_cased_title.pickle'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m#news_set/vocab_cased_title.pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0membedding\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0;34m\"glove/glove.6B.100d.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mwait_N\u001b[0m           \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     )\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/reuters_new/model_script/MIL/main_new_MIL300.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dim_word, dim, encoder, decoder, patience, max_epochs, finish_after, decay_c, clip_c, lrate, alpha_balance, n_words, n_words_lemma, maxlen, optimizer, batch_size, valid_batch_size, save_model, saveto, dispFreq, validFreq, saveFreq, use_dropout, reload_, verbose, types, cut_word, cut_news, keep_prob, datasets, valid_datasets, test_datasets, tech_data, dictionary, kb_dicts, embedding, dim_kb, RUN_NAME, wait_N)\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0mmodel_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m         \u001b[0mworddicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'news_set/vocab_cased_title.pickle'"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ############ use TITLE\n",
    "    model_name = 'models/'   #os.path.basename(os.path.dirname(os.path.realpath(__file__)))\n",
    "    train(\n",
    "    saveto           = './{}.npz'.format(model_name),\n",
    "    reload_          = False, #原来是true\n",
    "    dim_word         = 100, #embedding also change or 300 glove  \n",
    "    dim              = 50,\n",
    "    patience         = 10,\n",
    "    n_words          = 7634, #22671,  #s p500 46174 #ding 33976 40325\n",
    "    clip_c           = 10.,\n",
    "    lrate            = 0.04,\n",
    "    alpha_balance    = 0.04,\n",
    "    optimizer        = 'adam',\n",
    "    maxlen           = None,\n",
    "    batch_size       = 32,\n",
    "    valid_batch_size = 32,\n",
    "    dispFreq         = 20,\n",
    "    validFreq        = int(1411/32+1),#1421  #1391\n",
    "    saveFreq         = int(1411/32+1),\n",
    "    use_dropout      = True,\n",
    "    verbose          = False,\n",
    "    types            = 'title',\n",
    "    cut_word         = False,\n",
    "    cut_news         = 70,\n",
    "    keep_prob        = 0.5,\n",
    "    datasets         = ['news_set/train.csv',\n",
    "                       'price_set/train_label.csv'],\n",
    "    valid_datasets   = ['news_set/validate.csv',\n",
    "                        'price_set/validate_label.csv'],\n",
    "    test_datasets    = ['news_set/test.csv',\n",
    "                        'price_set/test_label.csv'],\n",
    "    #tech_data        = 'technical.csv',\n",
    "    dictionary       = 'news_set/vocab_cased_title.pickle',  #news_set/vocab_cased_title.pickle,\n",
    "    embedding        = \"glove/glove.6B.100d.txt\",\n",
    "    wait_N           = 1\n",
    "    )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
