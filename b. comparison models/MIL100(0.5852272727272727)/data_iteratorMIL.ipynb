{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import gzip\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delay(j, day):\n",
    "    return (datetime.strptime(j, '%Y-%m-%d') - timedelta(days=day)).strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "class TextIterator:\n",
    "    \"\"\"Simple Bitext iterator.\"\"\"\n",
    "    def __init__(self, instance, group_score,#min_instances=10,\n",
    "                 dict,types='title', #加emb\n",
    "                 batch_size=32,\n",
    "                 n_words=-1,\n",
    "                 #max_size = 200,\n",
    "                 cut_word=False, cut_news=False,\n",
    "                 shuffle=True, shuffle_sentence=False,  quiet=False):  # delay means how many days over the past\n",
    "\n",
    "        self.instance = pd.read_csv(instance).set_index('date')\n",
    "        self.instance = self.instance[types].groupby(self.instance.index).apply(list).apply(pd.Series).fillna(\n",
    "            '')  # group together\n",
    "        self.group_score = pd.read_csv(group_score).set_index('Date')\n",
    "        #self.min_instances = min_instances\n",
    "        #self.max_size = max_size  # max number of groups\n",
    "\n",
    "        \n",
    "        with open(dict, 'rb') as f:\n",
    "            self.dict = pkl.load(f)\n",
    "        self.down = 0\n",
    "        self.up = 0\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.n_words = n_words\n",
    "        self.shuffle = shuffle\n",
    "        self.shuffle_sentence = shuffle_sentence\n",
    "        self.types = types\n",
    "        self.end_of_data = False\n",
    "        self.cut_word = cut_word if cut_word else float('inf')  # cut the word\n",
    "        self.cut_news = cut_news if cut_news else None  # cut the sentence\n",
    "        self.instance_buffer = []\n",
    "        self.group_score_buffer = []\n",
    "        \n",
    "        self.k = batch_size * 20\n",
    "        self.index = 0\n",
    "        \n",
    "        \"\"\"if not quiet:\n",
    "            print('Total instances: ', len(self.instance), ' in ', len(self.group_score), ' groups')\n",
    "            print('Up instances: ', self.up, ' Down instances: ', self.down)\"\"\"\n",
    "        \n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def reset(self):\n",
    "        self.index = 0\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.end_of_data:\n",
    "            self.end_of_data = False\n",
    "            self.reset()\n",
    "            raise StopIteration\n",
    "\n",
    "        \n",
    "        temp = []\n",
    "        instances = []\n",
    "        instan_gath = []\n",
    "        group = []\n",
    "        group_scores = []\n",
    "        group_lengths = []  # needed to find limits of groups\n",
    "\n",
    "        assert len(self.instance_buffer) == len(self.group_score_buffer), 'Buffer size mismatch!'\n",
    "\n",
    "        if len(self.instance_buffer) == 0:\n",
    "            for j, i in enumerate(self.group_score.index.values[self.index:self.index + self.k]):  # j for count i for value\n",
    "                try:\n",
    "                    ss = list(filter(lambda x: self.cut_word > len(x.split()) > 0,\n",
    "                                     self.instance.loc[delay(i, 1)].values[:self.cut_news]))\n",
    "                    ll = self.group_score.loc[i].values\n",
    "                except KeyError as e:  # out of length\n",
    "                    print(i + ' ' + str(e))\n",
    "                    continue\n",
    "\n",
    "                self.instance_buffer.append(ss)\n",
    "                self.group_score_buffer.append(int(ll))\n",
    "            if 'j' in locals():\n",
    "                self.index += j + 1\n",
    "            ##TODO delete useless\n",
    "\n",
    "            if self.shuffle:\n",
    "                # sort by target buffer\n",
    "                tlen = np.array([len(t) for t in self.instance_buffer])\n",
    "                tidx = tlen.argsort()\n",
    "                # argsort the index from low to high\n",
    "                # shuffle mini-batch\n",
    "                tindex = []\n",
    "                ##Todo shuffle\n",
    "                small_index = list(range(int(math.ceil(len(tidx) * 1. / self.batch_size))))\n",
    "                random.shuffle(small_index)\n",
    "                for i in small_index:\n",
    "                    if (i + 1) * self.batch_size > len(tidx):\n",
    "                        tindex.extend(tidx[i * self.batch_size:])\n",
    "                    else:\n",
    "                        tindex.extend(tidx[i * self.batch_size:(i + 1) * self.batch_size])\n",
    "                tidx = tindex\n",
    "\n",
    "                _sbuf = [self.instance_buffer[i] for i in tidx]\n",
    "                _lbuf = [self.group_score_buffer[i] for i in tidx]\n",
    "\n",
    "                self.instance_buffer = _sbuf\n",
    "                self.group_score_buffer = _lbuf\n",
    "                ##TODO delete useless\n",
    "                del _sbuf, _lbuf\n",
    "            for i in self.instance_buffer:\n",
    "                temp.append([j.strip().split() for j in i])  # split words and save to array\n",
    "                \n",
    "            self.instance_buffer = temp\n",
    "            ##TODO delete useless\n",
    "            del temp#,original_temp\n",
    "            \n",
    "        if len(self.instance_buffer) == 0 or len(self.group_score_buffer) == 0:\n",
    "            self.end_of_data = False\n",
    "            self.reset()\n",
    "            raise StopIteration\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                # read from source file and map to word index\n",
    "                instance_temp = []\n",
    "                k = []\n",
    "                try:\n",
    "                    j = self.instance_buffer.pop(0)  # 1 day before N个instance, #每个“[[..]]”, 【[]],[],[]】\n",
    "                except IndexError:\n",
    "                    break\n",
    "                ##TODO do shuffle \n",
    "                if self.shuffle_sentence:\n",
    "                    np.random.shuffle(j)\n",
    "                for i in j:  # deal with 1 day before, each instance,一个[]\n",
    "                    ss = [self.dict[w] if w in self.dict else 1 for w in i]  # 1 means _UNK_  i:each instance,w:each word\n",
    "                    if self.n_words > 0:\n",
    "                        ss = [w if w < self.n_words else 1 for w in ss]  # 1 means _UNK_\n",
    "                    instance_temp.append(ss)  #ss(dict的数字！) = features(已*300) = one word, instance_temp = emb = #【[],[],[]..[]】\n",
    "                    #print(instance_temp) \n",
    "                    #instance_temp1 = np.pad(instance_temp,((self.max_size-len(instance_temp),0),(0,0)),'constant',constant_values = (0,0))\n",
    "                    #instances.append(instance_temp)  #instance_temp is one sentence  instances.append(instance_temp)\n",
    "\n",
    "                \n",
    "                # read label\n",
    "                instances.append(instance_temp) #instance_temp[[]],32个[[]]\n",
    "                instan_gath += instance_temp\n",
    "                # (XXXX) instances += instance_temp\n",
    "                #print('*'*80)  #32个循环\n",
    "                #print(np.shape(instan_gath))\n",
    "                \n",
    "                \n",
    "                score = self.group_score_buffer.pop(0)\n",
    "                group_scores.append(score)   #label\n",
    "                \n",
    "                ##TODO delete useless\n",
    "                del instance_temp\n",
    "\n",
    "                if len(group_scores) >= self.batch_size: #or d >= self.max_size:\n",
    "                    break\n",
    "        except IOError:\n",
    "            self.end_of_data = True\n",
    "        ####################################End of loop\n",
    "        \n",
    "        ################################## Can only be placed here!!!   \n",
    "        for i in range(len(instances)):\n",
    "            group_lengths.append(len(instances[i]))  #32-dim\n",
    "        maxlen__x = max(group_lengths)\n",
    "\n",
    "        if score == 0:  # for stats\n",
    "            self.down += 1\n",
    "        else:\n",
    "            self.up += 1\n",
    "\n",
    "        if len(group_scores) <= 0:\n",
    "            self.end_of_data = False\n",
    "            self.reset()\n",
    "            raise StopIteration\n",
    "        \n",
    "        \n",
    "        #print(instan_gath)\n",
    "        #print(np.shape(instan_gath))  = np.sum(group_lengths) (365,)\n",
    "        #X = np.array(instances, dtype='float16') \n",
    "        group_scores = np.array(group_scores, dtype='uint8')\n",
    "        #group_lengths = np.array(group_lengths, dtype='uint16')\n",
    "        #del instances  # memory save\n",
    "        #return X, instan_gath, group_scores, group_lengths #X list,list, array,array\n",
    "        #return instances, instan_gath,group_scores,maxlen__x# group_lengths\n",
    "        return instances,group_scores\n",
    "        #return source, label\n",
    "        \n",
    "        #返回3样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006-11-28 '2006-11-27'\n",
      "2006-12-26 '2006-12-25'\n",
      "2007-02-05 '2007-02-04'\n",
      "2007-02-20 '2007-02-19'\n",
      "2007-03-26 '2007-03-25'\n",
      "2007-04-02 '2007-04-01'\n",
      "2007-06-25 '2007-06-24'\n",
      "2007-07-16 '2007-07-15'\n",
      "2007-07-30 '2007-07-29'\n",
      "2007-09-10 '2007-09-09'\n",
      "2007-10-15 '2007-10-14'\n",
      "2007-10-22 '2007-10-21'\n",
      "2007-10-29 '2007-10-28'\n",
      "2007-11-26 '2007-11-25'\n",
      "2007-12-26 '2007-12-25'\n",
      "2008-01-07 '2008-01-06'\n",
      "2008-03-31 '2008-03-30'\n",
      "2008-04-07 '2008-04-06'\n",
      "2008-06-09 '2008-06-08'\n",
      "2008-06-23 '2008-06-22'\n",
      "2008-12-15 '2008-12-14'\n",
      "2008-12-26 '2008-12-25'\n",
      "2009-01-20 '2009-01-19'\n",
      "2009-02-02 '2009-02-01'\n",
      "2009-04-13 '2009-04-12'\n",
      "2009-04-27 '2009-04-26'\n",
      "train 0 length 32 (32,)\n",
      "train 1 length 32 (32,)\n",
      "train 2 length 32 (32,)\n",
      "train 3 length 32 (32,)\n",
      "train 4 length 32 (32,)\n",
      "train 5 length 32 (32,)\n",
      "train 6 length 32 (32,)\n",
      "train 7 length 32 (32,)\n",
      "train 8 length 32 (32,)\n",
      "train 9 length 32 (32,)\n",
      "train 10 length 32 (32,)\n",
      "train 11 length 32 (32,)\n",
      "train 12 length 32 (32,)\n",
      "train 13 length 32 (32,)\n",
      "train 14 length 32 (32,)\n",
      "train 15 length 32 (32,)\n",
      "train 16 length 32 (32,)\n",
      "train 17 length 32 (32,)\n",
      "train 18 length 32 (32,)\n",
      "train 19 length 6 (6,)\n",
      "2009-07-06 '2009-07-05'\n",
      "2009-07-13 '2009-07-12'\n",
      "2009-07-20 '2009-07-19'\n",
      "2009-08-20 '2009-08-19'\n",
      "2009-10-19 '2009-10-18'\n",
      "2009-10-26 '2009-10-25'\n",
      "2009-11-09 '2009-11-08'\n",
      "2009-11-27 '2009-11-26'\n",
      "2010-03-15 '2010-03-14'\n",
      "2010-04-12 '2010-04-11'\n",
      "2010-06-01 '2010-05-31'\n",
      "2010-08-09 '2010-08-08'\n",
      "2010-08-23 '2010-08-22'\n",
      "2011-01-10 '2011-01-09'\n",
      "2011-01-31 '2011-01-30'\n",
      "train 20 length 32 (32,)\n",
      "train 21 length 32 (32,)\n",
      "train 22 length 32 (32,)\n",
      "train 23 length 32 (32,)\n",
      "train 24 length 32 (32,)\n",
      "train 25 length 32 (32,)\n",
      "train 26 length 32 (32,)\n",
      "train 27 length 32 (32,)\n",
      "train 28 length 32 (32,)\n",
      "train 29 length 32 (32,)\n",
      "train 30 length 32 (32,)\n",
      "train 31 length 32 (32,)\n",
      "train 32 length 32 (32,)\n",
      "train 33 length 32 (32,)\n",
      "train 34 length 32 (32,)\n",
      "train 35 length 32 (32,)\n",
      "train 36 length 32 (32,)\n",
      "train 37 length 32 (32,)\n",
      "train 38 length 32 (32,)\n",
      "train 39 length 17 (17,)\n",
      "train 40 length 32 (32,)\n",
      "train 41 length 32 (32,)\n",
      "train 42 length 32 (32,)\n",
      "train 43 length 32 (32,)\n",
      "train 44 length 3 (3,)\n",
      "Validate 0 length 32 (32,)\n",
      "Validate 1 length 32 (32,)\n",
      "Validate 2 length 32 (32,)\n",
      "Validate 3 length 32 (32,)\n",
      "Validate 4 length 32 (32,)\n",
      "Validate 5 length 16 (16,)\n",
      "Test 0 length 32 (32,)\n",
      "Test 1 length 32 (32,)\n",
      "Test 2 length 32 (32,)\n",
      "Test 3 length 32 (32,)\n",
      "Test 4 length 32 (32,)\n",
      "Test 5 length 16 (16,)\n"
     ]
    }
   ],
   "source": [
    "#################################### ONE ###################################\n",
    "def main():\n",
    "    train = TextIterator('news_set/train.csv',\n",
    "                         'price_set/train_label.csv',\n",
    "                         #max_size = 200, # max number of groups\n",
    "                         dict='news_set/vocab_cased_title.pickle',\n",
    "                         types='title',\n",
    "                         n_words=43920,\n",
    "                         batch_size=32, cut_word=False, cut_news=False,\n",
    "                         shuffle=True,  quiet=False) \n",
    "    validate = TextIterator('news_set/validate.csv',\n",
    "                            'price_set/validate_label.csv',\n",
    "                            #max_size = 200,# max number of groups\n",
    "                            dict='news_set/vocab_cased_title.pickle',\n",
    "                            types='title',\n",
    "                            n_words=43920,\n",
    "                            batch_size=32, cut_word=False, cut_news=False,\n",
    "                            shuffle=True,  quiet=False)\n",
    "    test = TextIterator('news_set/test.csv',\n",
    "                        'price_set/test_label.csv',\n",
    "                        #max_size = 200, # max number of groups\n",
    "                        dict='news_set/vocab_cased_title.pickle',\n",
    "                        types='title',\n",
    "                        n_words=43920,\n",
    "                        batch_size=32, cut_word=False, cut_news=False,\n",
    "                        shuffle=True,  quiet=False)\n",
    "    \n",
    "    # cut news: max news number per day\n",
    "    #for i, (x, instance_gath, group_scores, maxlen__) in enumerate(train): \n",
    "    #    print(\"Train\", i,'Total instances: ', np.shape(instance_gath), ' of Max instances length: ', maxlen__, ' in ', len(group_scores), ' groups')\n",
    "    for i, (x, group_scores) in enumerate(train): #(array,list,array,array)原本x是instances,len(x)=32\n",
    "        #print(x)\n",
    "        #print(len(x)) #len(original)=32?个【[],[],】,len(originak_gath)=(320,\n",
    "        #print(instance_gath)\n",
    "        #print(len(x),len(x[0]),len(x[0][0]))\n",
    "        #print('*'* 80)\n",
    "        #print(\"Train\", i,'Total instances: ', np.shape(instance_gath), ' of Total group length: ', np.sum(group_lengths), ' in ', len(group_scores), ' groups')\n",
    "        print(\"train\", i, 'length', len(x), group_scores.shape)\n",
    "    for i, (x, group_scores) in enumerate(validate):\n",
    "        print(\"Validate\", i,'length', len(x), group_scores.shape)\n",
    "    for i, (x, group_scores) in enumerate(test):\n",
    "        print(\"Test\", i,'length', len(x), group_scores.shape)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006-11-28 '2006-11-27'\n",
      "2006-12-26 '2006-12-25'\n",
      "2007-02-05 '2007-02-04'\n",
      "2007-02-20 '2007-02-19'\n",
      "2007-03-26 '2007-03-25'\n",
      "2007-04-02 '2007-04-01'\n",
      "2007-06-25 '2007-06-24'\n",
      "2007-07-16 '2007-07-15'\n",
      "2007-07-30 '2007-07-29'\n",
      "2007-09-10 '2007-09-09'\n",
      "2007-10-15 '2007-10-14'\n",
      "2007-10-22 '2007-10-21'\n",
      "2007-10-29 '2007-10-28'\n",
      "2007-11-26 '2007-11-25'\n",
      "2007-12-26 '2007-12-25'\n",
      "2008-01-07 '2008-01-06'\n",
      "2008-03-31 '2008-03-30'\n",
      "2008-04-07 '2008-04-06'\n",
      "2008-06-09 '2008-06-08'\n",
      "2008-06-23 '2008-06-22'\n",
      "2008-12-15 '2008-12-14'\n",
      "2008-12-26 '2008-12-25'\n",
      "2009-01-20 '2009-01-19'\n",
      "2009-02-02 '2009-02-01'\n",
      "2009-04-13 '2009-04-12'\n",
      "2009-04-27 '2009-04-26'\n",
      "Train 0 Total instances:  (340,)  of Max instances length:  11  in  32  groups\n",
      "Train 1 Total instances:  (396,)  of Max instances length:  13  in  32  groups\n",
      "Train 2 Total instances:  (320,)  of Max instances length:  10  in  32  groups\n",
      "Train 3 Total instances:  (32,)  of Max instances length:  1  in  32  groups\n",
      "Train 4 Total instances:  (407,)  of Max instances length:  42  in  32  groups\n",
      "Train 5 Total instances:  (289,)  of Max instances length:  10  in  32  groups\n",
      "Train 6 Total instances:  (215,)  of Max instances length:  10  in  32  groups\n",
      "Train 7 Total instances:  (135,)  of Max instances length:  6  in  32  groups\n",
      "Train 8 Total instances:  (450,)  of Max instances length:  17  in  32  groups\n",
      "Train 9 Total instances:  (489,)  of Max instances length:  18  in  32  groups\n",
      "Train 10 Total instances:  (253,)  of Max instances length:  16  in  32  groups\n",
      "Train 11 Total instances:  (113,)  of Max instances length:  7  in  32  groups\n",
      "Train 12 Total instances:  (200,)  of Max instances length:  7  in  32  groups\n",
      "Train 13 Total instances:  (335,)  of Max instances length:  12  in  32  groups\n",
      "Train 14 Total instances:  (280,)  of Max instances length:  12  in  32  groups\n",
      "Train 15 Total instances:  (556,)  of Max instances length:  22  in  32  groups\n",
      "Train 16 Total instances:  (180,)  of Max instances length:  23  in  32  groups\n",
      "Train 17 Total instances:  (141,)  of Max instances length:  5  in  32  groups\n",
      "Train 18 Total instances:  (376,)  of Max instances length:  14  in  32  groups\n",
      "Train 19 Total instances:  (84,)  of Max instances length:  14  in  6  groups\n",
      "2009-07-06 '2009-07-05'\n",
      "2009-07-13 '2009-07-12'\n",
      "2009-07-20 '2009-07-19'\n",
      "2009-08-20 '2009-08-19'\n",
      "2009-10-19 '2009-10-18'\n",
      "2009-10-26 '2009-10-25'\n",
      "2009-11-09 '2009-11-08'\n",
      "2009-11-27 '2009-11-26'\n",
      "2010-03-15 '2010-03-14'\n",
      "2010-04-12 '2010-04-11'\n",
      "2010-06-01 '2010-05-31'\n",
      "2010-08-09 '2010-08-08'\n",
      "2010-08-23 '2010-08-22'\n",
      "2011-01-10 '2011-01-09'\n",
      "2011-01-31 '2011-01-30'\n",
      "Train 20 Total instances:  (251,)  of Max instances length:  8  in  32  groups\n",
      "Train 21 Total instances:  (126,)  of Max instances length:  4  in  32  groups\n",
      "Train 22 Total instances:  (1265,)  of Max instances length:  45  in  32  groups\n",
      "Train 23 Total instances:  (186,)  of Max instances length:  6  in  32  groups\n",
      "Train 24 Total instances:  (370,)  of Max instances length:  12  in  32  groups\n",
      "Train 25 Total instances:  (218,)  of Max instances length:  7  in  32  groups\n",
      "Train 26 Total instances:  (1532,)  of Max instances length:  50  in  32  groups\n",
      "Train 27 Total instances:  (2117,)  of Max instances length:  69  in  32  groups\n",
      "Train 28 Total instances:  (1831,)  of Max instances length:  59  in  32  groups\n",
      "Train 29 Total instances:  (274,)  of Max instances length:  9  in  32  groups\n",
      "Train 30 Total instances:  (33,)  of Max instances length:  2  in  32  groups\n",
      "Train 31 Total instances:  (1977,)  of Max instances length:  63  in  32  groups\n",
      "Train 32 Total instances:  (430,)  of Max instances length:  15  in  32  groups\n",
      "Train 33 Total instances:  (156,)  of Max instances length:  5  in  32  groups\n",
      "Train 34 Total instances:  (2372,)  of Max instances length:  80  in  32  groups\n",
      "Train 35 Total instances:  (1552,)  of Max instances length:  104  in  32  groups\n",
      "Train 36 Total instances:  (301,)  of Max instances length:  19  in  32  groups\n",
      "Train 37 Total instances:  (520,)  of Max instances length:  28  in  32  groups\n",
      "Train 38 Total instances:  (944,)  of Max instances length:  53  in  32  groups\n",
      "Train 39 Total instances:  (913,)  of Max instances length:  55  in  17  groups\n",
      "Train 40 Total instances:  (2413,)  of Max instances length:  93  in  32  groups\n",
      "Train 41 Total instances:  (718,)  of Max instances length:  88  in  32  groups\n",
      "Train 42 Total instances:  (1538,)  of Max instances length:  55  in  32  groups\n",
      "Train 43 Total instances:  (1920,)  of Max instances length:  64  in  32  groups\n",
      "Train 44 Total instances:  (196,)  of Max instances length:  66  in  3  groups\n",
      "Validate 0 Total instances:  (1923,)  of Max instances length:  63  in  32  groups\n",
      "Validate 1 Total instances:  (1434,)  of Max instances length:  92  in  32  groups\n",
      "Validate 2 Total instances:  (634,)  of Max instances length:  40  in  32  groups\n",
      "Validate 3 Total instances:  (1538,)  of Max instances length:  53  in  32  groups\n",
      "Validate 4 Total instances:  (1938,)  of Max instances length:  70  in  32  groups\n",
      "Validate 5 Total instances:  (1153,)  of Max instances length:  74  in  16  groups\n",
      "Test 0 Total instances:  (1267,)  of Max instances length:  48  in  32  groups\n",
      "Test 1 Total instances:  (2093,)  of Max instances length:  71  in  32  groups\n",
      "Test 2 Total instances:  (1369,)  of Max instances length:  97  in  32  groups\n",
      "Test 3 Total instances:  (1129,)  of Max instances length:  59  in  32  groups\n",
      "Test 4 Total instances:  (1758,)  of Max instances length:  62  in  32  groups\n",
      "Test 5 Total instances:  (836,)  of Max instances length:  54  in  16  groups\n"
     ]
    }
   ],
   "source": [
    "################################################### TWO ################################################\n",
    "def main():\n",
    "    train = TextIterator('news_set/train.csv',\n",
    "                         'price_set/train_label.csv',\n",
    "                         #max_size = 200, # max number of groups\n",
    "                         dict='news_set/vocab_cased_title.pickle',\n",
    "                         types='title',\n",
    "                         n_words=43920,\n",
    "                         batch_size=32, cut_word=False, cut_news=False,\n",
    "                         shuffle=True,  quiet=False) \n",
    "    validate = TextIterator('news_set/validate.csv',\n",
    "                            'price_set/validate_label.csv',\n",
    "                            #max_size = 200,# max number of groups\n",
    "                            dict='news_set/vocab_cased_title.pickle',\n",
    "                            types='title',\n",
    "                            n_words=43920,\n",
    "                            batch_size=32, cut_word=False, cut_news=False,\n",
    "                            shuffle=True,  quiet=False)\n",
    "    test = TextIterator('news_set/test.csv',\n",
    "                        'price_set/test_label.csv',\n",
    "                        #max_size = 200, # max number of groups\n",
    "                        dict='news_set/vocab_cased_title.pickle',\n",
    "                        types='title',\n",
    "                        n_words=43920,\n",
    "                        batch_size=32, cut_word=False, cut_news=False,\n",
    "                        shuffle=True,  quiet=False)\n",
    "    # cut news: max news number per day\n",
    "    #for i, (x, instance_gath, group_scores, maxlen__) in enumerate(train): \n",
    "    #    print(\"Train\", i,'Total instances: ', np.shape(instance_gath), ' of Max instances length: ', maxlen__, ' in ', len(group_scores), ' groups')\n",
    "    for i, (x, instance_gath, group_scores, max_lengths) in enumerate(train): #(array,list,array,array)原本x是instances,len(x)=32\n",
    "        #print(x)\n",
    "        #print(len(x)) #len(original)=32?个【[],[],】,len(originak_gath)=(320,\n",
    "        #print(instance_gath)\n",
    "        #print(len(x),len(x[0]),len(x[0][0]))\n",
    "        #print('*'* 80)\n",
    "        #print(\"Train\", i,'Total instances: ', np.shape(instance_gath), ' of Total group length: ', np.sum(group_lengths), ' in ', len(group_scores), ' groups')\n",
    "        print(\"Train\", i,'Total instances: ', np.shape(instance_gath), ' of Max instances length: ', max_lengths, ' in ', len(group_scores), ' groups')\n",
    "        #print('Positives: ', self.positives, ' Negatives: ', self.negatives)\n",
    "    for i, (x, instance_gath,group_scores, max_lengths) in enumerate(validate):\n",
    "        print(\"Validate\", i,'Total instances: ', np.shape(instance_gath), ' of Max instances length: ', max_lengths, ' in ', len(group_scores), ' groups')\n",
    "        #print(\"validate\", i,'Total instances: ', np.shape(instance_gath), ' of Total group length: ', group_lengths, ' in ', len(group_scores), ' groups')\n",
    "        #print(\"validate\", i, 'Total instances: ', np.sum(group_lengths), ' in ', len(group_scores), ' groups')\n",
    "    for i, (x, instance_gath,group_scores, max_lengths) in enumerate(test):\n",
    "        print(\"Test\", i,'Total instances: ', np.shape(instance_gath), ' of Max instances length: ', max_lengths,' in ', len(group_scores), ' groups')\n",
    "        #print(\"test\", i, 'Total instances: ', np.sum(group_lengths), ' in ', len(group_scores), ' groups')\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
