{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ updated in 25/11/2020\n",
    "########### 跑很多遍都是一个结果\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import re, os, glob\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import string\n",
    "from gensim.models import Phrases\n",
    "from gensim.utils import SaveLoad\n",
    "from gensim.models.phrases import Phraser\n",
    "from nltk.corpus import stopwords  # Import the stop word list\n",
    "import timeit\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "# from nltk import pos_tag, word_tokenize\n",
    "from nltk.tag import PerceptronTagger\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pywsd's Lemmatizer.\n",
    "porter = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()\n",
    "tagger = PerceptronTagger()\n",
    "pos_tag = tagger.tag\n",
    "tokenizer = RegexpTokenizer(r'\\.|\\w+')\n",
    "\n",
    "\n",
    "def lemmatize(ambiguous_word, pos=None, neverstem=True,\n",
    "              lemmatizer=wnl, stemmer=porter):\n",
    "    \"\"\"\n",
    "    Tries to convert a surface word into lemma, and if lemmatize word is not in\n",
    "    wordnet then try and convert surface word into its stem.\n",
    "    This is to handle the case where users input a surface word as an ambiguous\n",
    "    word and the surface word is a not a lemma.\n",
    "    \"\"\"\n",
    "    if pos:\n",
    "        lemma = lemmatizer.lemmatize(ambiguous_word, pos=pos)\n",
    "    else:\n",
    "        lemma = lemmatizer.lemmatize(ambiguous_word)\n",
    "    stem = stemmer.stem(ambiguous_word)\n",
    "    # Ensure that ambiguous word is a lemma.\n",
    "    if not wn.synsets(lemma):\n",
    "        if neverstem:\n",
    "            return ambiguous_word\n",
    "        if not wn.synsets(stem):\n",
    "            return ambiguous_word\n",
    "        else:\n",
    "            return stem\n",
    "    else:\n",
    "        return lemma\n",
    "\n",
    "\n",
    "def penn2morphy(penntag, returnNone=False):\n",
    "    morphy_tag = {'NN': wn.NOUN, 'JJ': wn.ADJ,\n",
    "                  'VB': wn.VERB, 'RB': wn.ADV}\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]\n",
    "    except:\n",
    "        return None if returnNone else ''\n",
    "\n",
    "\n",
    "def word_tokenize(text, tokenize=tokenizer):\n",
    "    return tokenize.tokenize(text.lower())  # doesn't remove stopwords\n",
    "    # return [w for w in tokenize.tokenize(text.lower()) if not w in stopwords.words(\"english\")]\n",
    "\n",
    "\n",
    "def lemmatize_sentence(sentence, neverstem=False, keepWordPOS=False,\n",
    "                       tokenizer=word_tokenize, postagger=pos_tag,\n",
    "                       lemmatizer=wnl, stemmer=porter):\n",
    "    words, lemmas, poss = [], [], []\n",
    "    for word, pos in postagger(sentence):  # change tokenizer(sentence) to sentence\n",
    "        pos = penn2morphy(pos)\n",
    "        lemmas.append(lemmatize(word.lower(), pos, neverstem,\n",
    "                                lemmatizer, stemmer))\n",
    "        poss.append(pos)\n",
    "        words.append(word)\n",
    "    if keepWordPOS:\n",
    "        return words, lemmas, [None if i == '' else i for i in poss]\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fil_sub(reviews, fill=None):\n",
    "    words = word_tokenize(str(reviews))  # tokenize and remove punctuation\n",
    "    if any(x in words for x in fill):\n",
    "        return reviews\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "def filter_news(title, bigram, trigram):\n",
    "    fill = set()\n",
    "    # sp = pd.read_csv('sp500.csv', names=['Symbol', 'Name', 'market', 'number'])\n",
    "    sp = pd.read_csv('sp100.csv')\n",
    "    sp = sp.dropna(axis=0, how='any')  # drop the row that's incomplete\n",
    "    sp['Symbol'] = sp['Symbol'].str.lower()\n",
    "    ##TODO the following steps make sure that all the symbols and company names are included,despite format\n",
    "    # TODO Do the phrase\n",
    "    sp['phrase'] = sp['Name'].apply(convert, args=(bigram, trigram, False, True, False)).replace([' \\. ', ' \\.'], ' ',\n",
    "                                                                                                 regex=True)\n",
    "    sp['phrase'] = sp['phrase'].replace(['\\\\bu s\\\\b', '\\\\bs p\\\\b', '\\\\bat t\\\\b', '\\\\b\\d+\\\\b'],\n",
    "                                        ['u_s', 's_p', 'at_t', 'xxx'],\n",
    "                                        regex=True)  # becareful of using inplace\n",
    "    sp['phrase'] = sp['phrase'].replace(\n",
    "        ['class_\\w', 'class \\w', ' inc\\\\b', ' corp\\\\b', ' company\\\\b', ' com\\\\b', ' group\\\\b', ' store\\\\b',\n",
    "         ' co\\\\b',\n",
    "         ' plc\\\\b', \"\\\\b\\w\\\\b\"],\n",
    "        '',\n",
    "        regex=True)\n",
    "    # TODO not do the phrase\n",
    "    sp['no_phrase'] = sp['Name'].apply(convert, args=(bigram, trigram, False, False, False)).replace([' \\. ', ' \\.'],\n",
    "                                                                                                     ' ',\n",
    "                                                                                                     regex=True)\n",
    "    sp['no_phrase'] = sp['no_phrase'].replace(['\\\\bu s\\\\b', '\\\\bs p\\\\b', '\\\\bat t\\\\b', '\\\\b\\d+\\\\b'],\n",
    "                                              ['u_s', 's_p', 'at_t', 'xxx'],\n",
    "                                              regex=True)  # becareful of using inplace\n",
    "    sp['no_phrase'] = sp['no_phrase'].replace(\n",
    "        ['class_\\w', 'class \\w', ' inc\\\\b', ' corp\\\\b', ' company\\\\b', ' com\\\\b', ' group\\\\b', ' store\\\\b',\n",
    "         ' co\\\\b',\n",
    "         ' plc\\\\b', \"\\\\b\\w\\\\b\"],\n",
    "        '',\n",
    "        regex=True)\n",
    "    ##TODO connet all together\n",
    "    sp['connect'] = sp['Name'].apply(convert, args=(bigram, trigram, False, False, False)).replace(\n",
    "        ['\\\\bu s\\\\b', '\\\\bs p\\\\b', '\\\\bat t\\\\b', '\\\\b\\d+\\\\b'],\n",
    "        ['u_s', 's_p', 'at_t', 'xxx'],\n",
    "        regex=True).replace(\n",
    "        [' \\. ', ' \\.', \"\\\\b\\w\\\\b\", 'class'], ' ',\n",
    "        regex=True).apply(\n",
    "        lambda x: '_'.join(x.split()))\n",
    "    ##TODO remove last word\n",
    "    sp['rm_last'] = sp['Name'].apply(convert, args=(bigram, trigram, False, False, False)).replace(\n",
    "        ['\\\\bu s\\\\b', '\\\\bs p\\\\b', '\\\\bat t\\\\b', '\\\\b\\d+\\\\b'],\n",
    "        ['u_s', 's_p', 'at_t', 'xxx'],\n",
    "        regex=True).replace(\n",
    "        [' \\. ', ' \\.', \"\\\\b\\w\\\\b\"], ' ',\n",
    "        regex=True).apply(lambda x: ' '.join(x.split()[:-1]))\n",
    "    sp['rm_last_connect'] = sp['rm_last'].apply(lambda x: '_'.join(x.split()))\n",
    "    sp['phrase_connect'] = sp['phrase'].apply(lambda x: '_'.join(x.split()))\n",
    "    sp['no_phrase_connect'] = sp['no_phrase'].apply(lambda x: '_'.join(x.split()))\n",
    "    fill.update(sp['no_phrase'].values.tolist())\n",
    "    fill.update(sp['phrase'].values.tolist())\n",
    "    fill.update(sp['Symbol'].values.tolist())\n",
    "    fill.update(sp['Name'].str.lower().values.tolist())\n",
    "    fill.update(sp['connect'].values.tolist())\n",
    "    fill.update(sp['rm_last'].values.tolist())\n",
    "    fill.update(sp['rm_last_connect'].values.tolist())\n",
    "    fill.update(sp['phrase_connect'].values.tolist())\n",
    "    fill.update(sp['no_phrase_connect'].values.tolist())\n",
    "    fill.update(\n",
    "        ['us', 'standardpoor', 'america', 'exxon', 'wall_st', 'wall_street', 'wall st', 'wall street', 'u_s', 'j_j',\n",
    "         'h_r', 'at_t', 'p_g', 'r_d', 'dow_jones', 'b_l', 'h_m', 's_p', 'amazon', 'exxon_mobil'])\n",
    "    fill = list(filter(None, fill))\n",
    "    print('length of total filter', len(fill))\n",
    "    title_select = title.groupby(title.index).apply(list).apply(pd.Series).fillna('')\n",
    "    for i in title_select.index:\n",
    "        if len(list(filter(None, title_select.loc[i].values))) > 1:\n",
    "            try:\n",
    "                title.loc[i] = title.loc[i].apply(fil_sub, fill=fill)\n",
    "            except AttributeError as e:\n",
    "                print(i + ' ' + str(e))\n",
    "\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start processing Ding_abstract data\n",
      "original shape (553870, 3)\n"
     ]
    }
   ],
   "source": [
    "types = ['title', 'abstract','article']\n",
    "start = timeit.default_timer()\n",
    "print('start processing Ding_abstract data')\n",
    "article = defaultdict(list)\n",
    "with open('news_title/reuters_news.json',\"r\") as data:  # title+ abstract + article\n",
    "    title = pd.DataFrame(json.loads(line, strict=False) for line in data).set_index('date')\n",
    "    \n",
    "with open('news_title/bloomberg_news.json',\"r\") as data:  # title+ abstract + article\n",
    "    bloomberg = pd.DataFrame(json.loads(line, strict=False) for line in data).set_index('date')\n",
    "\n",
    "title = title.append(bloomberg)\n",
    "print('original shape', title.shape) #original shape (553870, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-11-16</th>\n",
       "      <td>Olympus plans $3.4 billion debt reduction: Nik...</td>\n",
       "      <td>(Reuters) - Japan's disgraced Olympus Corp ( ...</td>\n",
       "      <td>Olympus's bank creditors are crucial to its p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-16</th>\n",
       "      <td>Swiss cabinet in move to inform U.S. bank clie...</td>\n",
       "      <td>ZURICH  (Reuters) - The Swiss cabinet approve...</td>\n",
       "      <td>\"The amendment should ensure that the procedu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-16</th>\n",
       "      <td>Euro zone Oct inflation 3 percent; seen falling.</td>\n",
       "      <td>BRUSSELS  (Reuters) - Euro zone inflation hel...</td>\n",
       "      <td>Now at a three-year high, consumer prices in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-16</th>\n",
       "      <td>Qantas hopeful on deal with unions, shares rally.</td>\n",
       "      <td>SYDNEY  (Reuters) - Australia's Qantas Airway...</td>\n",
       "      <td>The optimistic comments, just days before the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-16</th>\n",
       "      <td>More euro zone integration a must for euro sur...</td>\n",
       "      <td>STRASBOURG, France  (Reuters) - The euro zone...</td>\n",
       "      <td>\"Without this increased integration, converge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-16</th>\n",
       "      <td>for traders.</td>\n",
       "      <td>LONDON  (Reuters) - Life is not easy for the ...</td>\n",
       "      <td>There are no pumped-up traders cheering from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-16</th>\n",
       "      <td>Citigroup could cut up to 3,000 jobs: report.</td>\n",
       "      <td>NEW YORK  (Reuters) - Citigroup In ( C.N )c i...</td>\n",
       "      <td>The job cuts are intended to help cut Citigro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-16</th>\n",
       "      <td>Economy shows signs of momentum in 4th quarter.</td>\n",
       "      <td>OTTAWA  (Reuters) - Canadian consumers spent ...</td>\n",
       "      <td>Retail sales grew by 1 percent in the month, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-16</th>\n",
       "      <td>Seaway oil pipe to be reversed after Enbridge ...</td>\n",
       "      <td>(Reuters) - Enbridge Inc ( ENB.TO ) surged pa...</td>\n",
       "      <td>Enbridge and Enterprise Products Partners ( E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-16</th>\n",
       "      <td>October consumer prices fall, giving Fed more ...</td>\n",
       "      <td>WASHINGTON  (Reuters) - Consumer prices fell ...</td>\n",
       "      <td>For now, economic growth is gaining traction ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        title  \\\n",
       "date                                                            \n",
       "2011-11-16  Olympus plans $3.4 billion debt reduction: Nik...   \n",
       "2011-11-16  Swiss cabinet in move to inform U.S. bank clie...   \n",
       "2011-11-16   Euro zone Oct inflation 3 percent; seen falling.   \n",
       "2011-11-16  Qantas hopeful on deal with unions, shares rally.   \n",
       "2011-11-16  More euro zone integration a must for euro sur...   \n",
       "2011-11-16                                       for traders.   \n",
       "2011-11-16      Citigroup could cut up to 3,000 jobs: report.   \n",
       "2011-11-16    Economy shows signs of momentum in 4th quarter.   \n",
       "2011-11-16  Seaway oil pipe to be reversed after Enbridge ...   \n",
       "2011-11-16  October consumer prices fall, giving Fed more ...   \n",
       "\n",
       "                                                     abstract  \\\n",
       "date                                                            \n",
       "2011-11-16   (Reuters) - Japan's disgraced Olympus Corp ( ...   \n",
       "2011-11-16   ZURICH  (Reuters) - The Swiss cabinet approve...   \n",
       "2011-11-16   BRUSSELS  (Reuters) - Euro zone inflation hel...   \n",
       "2011-11-16   SYDNEY  (Reuters) - Australia's Qantas Airway...   \n",
       "2011-11-16   STRASBOURG, France  (Reuters) - The euro zone...   \n",
       "2011-11-16   LONDON  (Reuters) - Life is not easy for the ...   \n",
       "2011-11-16   NEW YORK  (Reuters) - Citigroup In ( C.N )c i...   \n",
       "2011-11-16   OTTAWA  (Reuters) - Canadian consumers spent ...   \n",
       "2011-11-16   (Reuters) - Enbridge Inc ( ENB.TO ) surged pa...   \n",
       "2011-11-16   WASHINGTON  (Reuters) - Consumer prices fell ...   \n",
       "\n",
       "                                                      article  \n",
       "date                                                           \n",
       "2011-11-16   Olympus's bank creditors are crucial to its p...  \n",
       "2011-11-16   \"The amendment should ensure that the procedu...  \n",
       "2011-11-16   Now at a three-year high, consumer prices in ...  \n",
       "2011-11-16   The optimistic comments, just days before the...  \n",
       "2011-11-16   \"Without this increased integration, converge...  \n",
       "2011-11-16   There are no pumped-up traders cheering from ...  \n",
       "2011-11-16   The job cuts are intended to help cut Citigro...  \n",
       "2011-11-16   Retail sales grew by 1 percent in the month, ...  \n",
       "2011-11-16   Enbridge and Enterprise Products Partners ( E...  \n",
       "2011-11-16   For now, economic growth is gaining traction ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO don't do this if want to use character level\n",
    "title['title'] = title['title'].apply(lambda x: [x])\n",
    "title['abstract'] = title['abstract'].apply(lambda x: [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after dropping empty abstract and articles, first drop nan (553870, 3)\n"
     ]
    }
   ],
   "source": [
    "##TODO drop nan\n",
    "title = title.dropna(axis=0, how='any')  # drop the row that's incomplete\n",
    "title = title.sort_index()\n",
    "print('after dropping empty abstract and articles, first drop nan', title.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = title.applymap(lambda x: '.'.join(x))\n",
    "title = title.replace(\n",
    "    ['corrected', 'UPDATE\\s\\d-', \"'s\", 'update xxx', 'wrapup xxx', 'factbox', 'instant view', 'snap analysis',\n",
    "     'exclusive',\n",
    "     'timeline', 'highlights', 'correction', 'scenarios', 'analysis'], '', regex=True)  # becareful of using inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = title.replace(['\\\\bus\\\\b', '\\\\bu s\\\\b', \"\\\\bu_s\\\\b\"], 'america', regex=True)  # becareful of using inplace\n",
    "#title = title.replace(['us', 'u s', \"u_s\"], 'america', regex=True)  # becareful of using inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = title.replace(['\\\\buk\\\\b', '\\\\bu k\\\\b', \"\\\\bu_k\\\\b\"], 'british', regex=True)  # becareful of using inplace\n",
    "#title = title.replace(['uk', 'u k', \"u_k\"], 'british', regex=True)  # becareful of using inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = title.replace(['\\\\bs p\\\\b', '\\\\bs_p\\\\b', \"\\\\bs_p xxx\\\\b\"], 'standardpoor',regex=True)  # becareful of using inplace\n",
    "#title = title.replace(['s p', 's_p', \"s_p xxx\"], 'standardpoor',regex=True)  # becareful of using inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = title.replace(['\\ss\\s'], ' ', regex=True)  # becareful of using inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = title.replace(\n",
    "    ['\\\\bwo not\\\\b', '\\\\bbln\\\\b', '\\\\bmln\\\\b', '\\\\bpct\\\\b', '\\\\bs korea\\\\b', '\\\\bn korea\\\\b', '3rd', '2nd', '1st',\n",
    "     '4th',\n",
    "     '\\\\bq1\\\\b',\n",
    "     '\\\\bq2\\\\b', '\\\\bq3\\\\b', '\\\\bq4\\\\b', '\\\\bwall street\\\\b', '\\\\bisnt\\\\b', '\\\\b1st_', '\\\\b2nd_', '\\\\b3rd_',\n",
    "     '\\\\b4th_',\n",
    "     '\\\\bfirst_', '\\\\bsecond_', '\\\\bthird_', '\\\\bfourth_'],\n",
    "    ['would not', 'billion', 'million', 'percent', 'south_korea', 'north_korea', 'third', 'second', 'first',\n",
    "     'fourth',\n",
    "     'first quarter', 'second quarter', 'third quarter', 'fourth quarter', 'wall_street', 'is not', 'first ',\n",
    "     'second ', 'third ', 'fourth ', 'first ', 'second ', 'third ', 'fourth '],\n",
    "    regex=True)  # becareful of using inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = title.replace(['qtr', 'quarterly'], 'quarter', regex=True)  # becareful of using inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = title.replace(\n",
    "    ['\\\\bj j\\\\b', '\\\\bh r\\\\b', '\\\\bat t\\\\b', '\\\\bp g\\\\b', '\\\\br d\\\\b', 'dow jones', '\\\\bdow\\\\b',\n",
    "     '\\\\bb l\\\\b',\n",
    "     '\\\\bh m\\\\b', ' _ ', '\\\\b\\st\\\\b'],\n",
    "    ['j_j', 'h_r', 'at_t', 'p_g', 'r_d', 'dow_jones', 'dow_jones', 'b_l', 'h_m', ' and ', 'street'],\n",
    "    regex=True)  # becareful of using inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = title.replace(['\\d+\\S\\d+', 'xxx xxx', 'xxx xxx xxx'], 'xxx',\n",
    "                      regex=True)  # becareful of using inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-10-20</th>\n",
       "      <td>Hey buddy, can you spare $xxx for a Google share?</td>\n",
       "      <td>SAN FRANCISCO/NEW YORK  (Reuters) - Wall Stre...</td>\n",
       "      <td>. .B.r.o.k.e.r.s. .w.e.r.e. .r.e.s.p.o.n.d.i....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-20</th>\n",
       "      <td>Exxon Mobil offers plan to end Alaska dispute.</td>\n",
       "      <td>ANCHORAGE, Alaska  (Reuters) - Exxon Mobil ( ...</td>\n",
       "      <td>. .I.n. .a. .p.r.o.p.o.s.a.l. .s.e.n.t. .e.a....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-20</th>\n",
       "      <td>Inco Net Soars on Higher Metal Prices, Breakup...</td>\n",
       "      <td>Inco Ltd., the Canadian nickel producer being ...</td>\n",
       "      <td>N.e.t. .i.n.c.o.m.e. .j.u.m.p.e.d. .t.o. .$.xx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-21</th>\n",
       "      <td>AOL CEO says sales may shrink for two years -p...</td>\n",
       "      <td>FRANKFURT  (Reuters) - Internet service provi...</td>\n",
       "      <td>. .\".M.a.y.b.e. .a.n.o.t.h.e.r. .t.w.o. .y.e....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-21</th>\n",
       "      <td>Jim Cramer: Diageo, Anheuser-Busch, Monster Wo...</td>\n",
       "      <td>Jim Cramer  recommended that viewers buy share...</td>\n",
       "      <td>D.i.a.g.e.o. .i.s. .s.i.m.i.l.a.r. .t.o. . .G....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-26</th>\n",
       "      <td>DBS, ABN Said to Make Final Bids for SocGen’s ...</td>\n",
       "      <td>DBS Group Holdings Ltd. (DBS)  and  ABN Amro  ...</td>\n",
       "      <td>B.i.d.s. .s.u.b.m.i.t.t.e.d. .y.e.s.t.e.r.d.a....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-26</th>\n",
       "      <td>Taiwan Bond Yield Falls to Three-Week Low as O...</td>\n",
       "      <td>Taiwan ’s 10-year bonds gained, driving the yi...</td>\n",
       "      <td>I.n.d.u.s.t.r.i.a.l. .p.r.o.d.u.c.t.i.o.n. .c....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-26</th>\n",
       "      <td>Billionaire Said to Consider IPO for Owner of ...</td>\n",
       "      <td>Malaysian billionaire Vincent Tan is consideri...</td>\n",
       "      <td>T.a.n. .i.s. .h.o.l.d.i.n.g. .p.r.e.l.i.m.i.n....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-26</th>\n",
       "      <td>Canada Grain Exports From Vancouver Seen Risin...</td>\n",
       "      <td>Canadian grain shipments from Vancouver, the n...</td>\n",
       "      <td>G.r.a.i.n. .e.x.p.o.r.t.e.d. .t.h.r.o.u.g.h. ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-26</th>\n",
       "      <td>India’s Nifty Index Futures Decline Amid Slowi...</td>\n",
       "      <td>Indian stock-index futures fell after the benc...</td>\n",
       "      <td>S.G.X. .C.N.X. .N.i.f.t.y. .I.n.d.e.x. .f.u.t....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>553870 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        title  \\\n",
       "date                                                            \n",
       "2006-10-20  Hey buddy, can you spare $xxx for a Google share?   \n",
       "2006-10-20     Exxon Mobil offers plan to end Alaska dispute.   \n",
       "2006-10-20  Inco Net Soars on Higher Metal Prices, Breakup...   \n",
       "2006-10-21  AOL CEO says sales may shrink for two years -p...   \n",
       "2006-10-21  Jim Cramer: Diageo, Anheuser-Busch, Monster Wo...   \n",
       "...                                                       ...   \n",
       "2013-11-26  DBS, ABN Said to Make Final Bids for SocGen’s ...   \n",
       "2013-11-26  Taiwan Bond Yield Falls to Three-Week Low as O...   \n",
       "2013-11-26  Billionaire Said to Consider IPO for Owner of ...   \n",
       "2013-11-26  Canada Grain Exports From Vancouver Seen Risin...   \n",
       "2013-11-26  India’s Nifty Index Futures Decline Amid Slowi...   \n",
       "\n",
       "                                                     abstract  \\\n",
       "date                                                            \n",
       "2006-10-20   SAN FRANCISCO/NEW YORK  (Reuters) - Wall Stre...   \n",
       "2006-10-20   ANCHORAGE, Alaska  (Reuters) - Exxon Mobil ( ...   \n",
       "2006-10-20  Inco Ltd., the Canadian nickel producer being ...   \n",
       "2006-10-21   FRANKFURT  (Reuters) - Internet service provi...   \n",
       "2006-10-21  Jim Cramer  recommended that viewers buy share...   \n",
       "...                                                       ...   \n",
       "2013-11-26  DBS Group Holdings Ltd. (DBS)  and  ABN Amro  ...   \n",
       "2013-11-26  Taiwan ’s 10-year bonds gained, driving the yi...   \n",
       "2013-11-26  Malaysian billionaire Vincent Tan is consideri...   \n",
       "2013-11-26  Canadian grain shipments from Vancouver, the n...   \n",
       "2013-11-26  Indian stock-index futures fell after the benc...   \n",
       "\n",
       "                                                      article  \n",
       "date                                                           \n",
       "2006-10-20   . .B.r.o.k.e.r.s. .w.e.r.e. .r.e.s.p.o.n.d.i....  \n",
       "2006-10-20   . .I.n. .a. .p.r.o.p.o.s.a.l. .s.e.n.t. .e.a....  \n",
       "2006-10-20  N.e.t. .i.n.c.o.m.e. .j.u.m.p.e.d. .t.o. .$.xx...  \n",
       "2006-10-21   . .\".M.a.y.b.e. .a.n.o.t.h.e.r. .t.w.o. .y.e....  \n",
       "2006-10-21  D.i.a.g.e.o. .i.s. .s.i.m.i.l.a.r. .t.o. . .G....  \n",
       "...                                                       ...  \n",
       "2013-11-26  B.i.d.s. .s.u.b.m.i.t.t.e.d. .y.e.s.t.e.r.d.a....  \n",
       "2013-11-26  I.n.d.u.s.t.r.i.a.l. .p.r.o.d.u.c.t.i.o.n. .c....  \n",
       "2013-11-26  T.a.n. .i.s. .h.o.l.d.i.n.g. .p.r.e.l.i.m.i.n....  \n",
       "2013-11-26  G.r.a.i.n. .e.x.p.o.r.t.e.d. .t.h.r.o.u.g.h. ....  \n",
       "2013-11-26  S.G.X. .C.N.X. .N.i.f.t.y. .I.n.d.e.x. .f.u.t....  \n",
       "\n",
       "[553870 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(reviews, bigram, trigram, remove_stopwords=True, phrase=True, lemma=True):\n",
    "    # letters_only = re.sub(\"[^a-zA-Z0-9]\", \" \", str(reviews))\n",
    "    # words = list(filter(None, letters_only.lower().split()))\n",
    "    words = word_tokenize(reviews)  # tokenize and remove punctuation\n",
    "    if remove_stopwords:  # remove stopwords\n",
    "        words = [w for w in words if not w in stopwords.words(\"english\")]\n",
    "    if phrase is True:\n",
    "        words = trigram[bigram[words]]  # to phrase\n",
    "    if lemma is True:\n",
    "        words = lemmatize_sentence(words)  # lemma\n",
    "    return \" \".join(words)  # + ' .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dictionary(filepaths, dst_path, vocab):\n",
    "    #build_dictionary(title, path, 'title'/'abstract')\n",
    "    word_freqs = OrderedDict()\n",
    "    print('processing the vocab cases for ' + vocab)\n",
    "    for i in filepaths[vocab]:  #delete value\n",
    "        words_in = i.strip().split(' ')\n",
    "        for w in words_in:\n",
    "            if w not in word_freqs:\n",
    "                word_freqs[w] = 0\n",
    "            word_freqs[w] += 1\n",
    "    print('before dropping the words that occurs less than 5 times', len(word_freqs))\n",
    "    \n",
    "    for key, value in list(word_freqs.items()):\n",
    "        if value < 5:\n",
    "            del word_freqs[key]\n",
    "    \n",
    "    words = list(word_freqs.keys())\n",
    "    freqs = list(word_freqs.values())\n",
    "\n",
    "    sorted_idx = np.argsort(freqs)\n",
    "    sorted_words = [words[ii] for ii in sorted_idx[::-1]]\n",
    "\n",
    "    worddict = OrderedDict()\n",
    "    worddict['_PAD_'] = 0  # default, padding\n",
    "    worddict['_UNK_'] = 1  # out-of-vocabulary\n",
    "    worddict['_BOS_'] = 2  # begin of sentence token\n",
    "    worddict['_EOS_'] = 3  # end of sentence token\n",
    "\n",
    "    for ii, ww in enumerate(sorted_words):\n",
    "        worddict[ww] = ii + 4\n",
    "\n",
    "    with open('vocab_cased_new_' + vocab + '.pickle', 'wb') as f:\n",
    "        pkl.dump(worddict, f)\n",
    "\n",
    "    print('Dict size', len(worddict))\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = SaveLoad.load(\"big_phrase.pickle\")\n",
    "trigram = SaveLoad.load(\"trig_phrase.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish dealing with manual replace\n",
      "after dropping title is (529694, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"for i in types:\\n    # title[i] = title[i].str.replace('[{}]'.format(string.punctuation), ' ')\\n    title[i] = title[i].apply(convert, args=(bigram, trigram, False, False, False))\\n    title = title.drop_duplicates(subset=[i], keep='first')\\n    print('after dropping ' + i + ' is {}'.format(title.shape)) #(529922, 3),(511271, 3)\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##TODO only work on title\n",
    "\n",
    "print('finish dealing with manual replace')\n",
    "title['title'] = title['title'].apply(convert, args=(bigram, trigram, False, False, True))\n",
    "title = title.drop_duplicates(subset='title', keep='first')\n",
    "print('after dropping ' + 'title' + ' is {}'.format(title.shape))\n",
    "\n",
    "\"\"\"for i in types:\n",
    "    # title[i] = title[i].str.replace('[{}]'.format(string.punctuation), ' ')\n",
    "    title[i] = title[i].apply(convert, args=(bigram, trigram, False, False, False))\n",
    "    title = title.drop_duplicates(subset=[i], keep='first')\n",
    "    print('after dropping ' + i + ' is {}'.format(title.shape)) #(529922, 3),(511271, 3)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-2c83884bdb9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m##TODO change the news that's too short to nan, only use when processing abstract and article\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtitle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# title['abstract'] = title['abstract'].apply(lambda x: x if len(x) >= 100 else np.nan)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# title['article'] = title['article'].apply(lambda x: x if len(x) >= 100 else np.nan)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m##TODO filter the news\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3847\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3848\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-2c83884bdb9f>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m##TODO change the news that's too short to nan, only use when processing abstract and article\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtitle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# title['abstract'] = title['abstract'].apply(lambda x: x if len(x) >= 100 else np.nan)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# title['article'] = title['article'].apply(lambda x: x if len(x) >= 100 else np.nan)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m##TODO filter the news\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "##TODO change the news that's too short to nan, only use when processing abstract and article\n",
    "title['title'] = title['title'].apply(lambda x: x if len(x.split()) > 2 else np.nan)\n",
    "# title['abstract'] = title['abstract'].apply(lambda x: x if len(x) >= 100 else np.nan)\n",
    "# title['article'] = title['article'].apply(lambda x: x if len(x) >= 100 else np.nan)\n",
    "##TODO filter the news\n",
    "print('start the filter process')\n",
    "title['title'] = filter_news(title['title'], bigram, trigram)\n",
    "##TODO drop nan\n",
    "#title = title.dropna(axis=0, how='any')  # drop the row that's incomplete\n",
    "#print('after dropping incomplete rows, second drop nan', title.shape)\n",
    "# title = title.applymap(lambda x: x.split('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-10-20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SAN FRANCISCO/NEW YORK  (Reuters) - Wall Stre...</td>\n",
       "      <td>. .B.r.o.k.e.r.s. .w.e.r.e. .r.e.s.p.o.n.d.i....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-20</th>\n",
       "      <td>exxon mobil offer plan to end alaska dispute .</td>\n",
       "      <td>ANCHORAGE, Alaska  (Reuters) - Exxon Mobil ( ...</td>\n",
       "      <td>. .I.n. .a. .p.r.o.p.o.s.a.l. .s.e.n.t. .e.a....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Inco Ltd., the Canadian nickel producer being ...</td>\n",
       "      <td>N.e.t. .i.n.c.o.m.e. .j.u.m.p.e.d. .t.o. .$.xx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>FRANKFURT  (Reuters) - Internet service provi...</td>\n",
       "      <td>. .\".M.a.y.b.e. .a.n.o.t.h.e.r. .t.w.o. .y.e....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Jim Cramer  recommended that viewers buy share...</td>\n",
       "      <td>D.i.a.g.e.o. .i.s. .s.i.m.i.l.a.r. .t.o. . .G....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>DBS Group Holdings Ltd. (DBS)  and  ABN Amro  ...</td>\n",
       "      <td>B.i.d.s. .s.u.b.m.i.t.t.e.d. .y.e.s.t.e.r.d.a....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-26</th>\n",
       "      <td>taiwan bond yield fall to three week low a out...</td>\n",
       "      <td>Taiwan ’s 10-year bonds gained, driving the yi...</td>\n",
       "      <td>I.n.d.u.s.t.r.i.a.l. .p.r.o.d.u.c.t.i.o.n. .c....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Malaysian billionaire Vincent Tan is consideri...</td>\n",
       "      <td>T.a.n. .i.s. .h.o.l.d.i.n.g. .p.r.e.l.i.m.i.n....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-26</th>\n",
       "      <td>canada grain export from vancouver see rise to...</td>\n",
       "      <td>Canadian grain shipments from Vancouver, the n...</td>\n",
       "      <td>G.r.a.i.n. .e.x.p.o.r.t.e.d. .t.h.r.o.u.g.h. ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Indian stock-index futures fell after the benc...</td>\n",
       "      <td>S.G.X. .C.N.X. .N.i.f.t.y. .I.n.d.e.x. .f.u.t....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>529694 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        title  \\\n",
       "date                                                            \n",
       "2006-10-20                                                NaN   \n",
       "2006-10-20     exxon mobil offer plan to end alaska dispute .   \n",
       "2006-10-20                                                NaN   \n",
       "2006-10-21                                                NaN   \n",
       "2006-10-21                                                NaN   \n",
       "...                                                       ...   \n",
       "2013-11-26                                                NaN   \n",
       "2013-11-26  taiwan bond yield fall to three week low a out...   \n",
       "2013-11-26                                                NaN   \n",
       "2013-11-26  canada grain export from vancouver see rise to...   \n",
       "2013-11-26                                                NaN   \n",
       "\n",
       "                                                     abstract  \\\n",
       "date                                                            \n",
       "2006-10-20   SAN FRANCISCO/NEW YORK  (Reuters) - Wall Stre...   \n",
       "2006-10-20   ANCHORAGE, Alaska  (Reuters) - Exxon Mobil ( ...   \n",
       "2006-10-20  Inco Ltd., the Canadian nickel producer being ...   \n",
       "2006-10-21   FRANKFURT  (Reuters) - Internet service provi...   \n",
       "2006-10-21  Jim Cramer  recommended that viewers buy share...   \n",
       "...                                                       ...   \n",
       "2013-11-26  DBS Group Holdings Ltd. (DBS)  and  ABN Amro  ...   \n",
       "2013-11-26  Taiwan ’s 10-year bonds gained, driving the yi...   \n",
       "2013-11-26  Malaysian billionaire Vincent Tan is consideri...   \n",
       "2013-11-26  Canadian grain shipments from Vancouver, the n...   \n",
       "2013-11-26  Indian stock-index futures fell after the benc...   \n",
       "\n",
       "                                                      article  \n",
       "date                                                           \n",
       "2006-10-20   . .B.r.o.k.e.r.s. .w.e.r.e. .r.e.s.p.o.n.d.i....  \n",
       "2006-10-20   . .I.n. .a. .p.r.o.p.o.s.a.l. .s.e.n.t. .e.a....  \n",
       "2006-10-20  N.e.t. .i.n.c.o.m.e. .j.u.m.p.e.d. .t.o. .$.xx...  \n",
       "2006-10-21   . .\".M.a.y.b.e. .a.n.o.t.h.e.r. .t.w.o. .y.e....  \n",
       "2006-10-21  D.i.a.g.e.o. .i.s. .s.i.m.i.l.a.r. .t.o. . .G....  \n",
       "...                                                       ...  \n",
       "2013-11-26  B.i.d.s. .s.u.b.m.i.t.t.e.d. .y.e.s.t.e.r.d.a....  \n",
       "2013-11-26  I.n.d.u.s.t.r.i.a.l. .p.r.o.d.u.c.t.i.o.n. .c....  \n",
       "2013-11-26  T.a.n. .i.s. .h.o.l.d.i.n.g. .p.r.e.l.i.m.i.n....  \n",
       "2013-11-26  G.r.a.i.n. .e.x.p.o.r.t.e.d. .t.h.r.o.u.g.h. ....  \n",
       "2013-11-26  S.G.X. .C.N.X. .N.i.f.t.y. .I.n.d.e.x. .f.u.t....  \n",
       "\n",
       "[529694 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after dropping incomplete rows, second drop nan (71966, 3)\n"
     ]
    }
   ],
   "source": [
    "##TODO drop nan\n",
    "title = title.dropna(axis=0, how='any')  # drop the row that's incomplete\n",
    "print('after dropping incomplete rows, second drop nan', title.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-10-20</th>\n",
       "      <td>exxon mobil offer plan to end alaska dispute .</td>\n",
       "      <td>ANCHORAGE, Alaska  (Reuters) - Exxon Mobil ( ...</td>\n",
       "      <td>. .I.n. .a. .p.r.o.p.o.s.a.l. .s.e.n.t. .e.a....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-23</th>\n",
       "      <td>royal dutch bid for shell canada low sharehold...</td>\n",
       "      <td>CALGARY, Alberta  (Reuters) - One of Shell Ca...</td>\n",
       "      <td>.G.a.r.e.y. .A.i.t.k.e.n.,. .a. .p.o.r.t.f.o....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-23</th>\n",
       "      <td>dow end at record high texas instrument off la...</td>\n",
       "      <td>NEW YORK  (Reuters) - U.S. stocks rallied on ...</td>\n",
       "      <td>.S.h.a.r.e.s. .o.f. .W.a.l.-.M.a.r.t. .h.i.t....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-23</th>\n",
       "      <td>shell look to buy out canada unit for c xxx bi...</td>\n",
       "      <td>CALGARY/LONDON  (Reuters) - Royal Dutch Shell...</td>\n",
       "      <td>.S.h.e.l.l. .s.a.i.d. .i.n. .a. .s.t.a.t.e.m....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-23</th>\n",
       "      <td>ford be review all product brand ceo .</td>\n",
       "      <td>DETROIT  (Reuters) - Ford Motor Co. is commit...</td>\n",
       "      <td>.T.h.e. .a.u.t.o.m.a.k.e.r. .w.i.l.l. .\".l.o....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-25</th>\n",
       "      <td>statoil to be selective in pick exploration ta...</td>\n",
       "      <td>Statoil ASA (STL) , Norway’s biggest oil and g...</td>\n",
       "      <td>S.t.a.t.o.i.l. .w.i.l.l. .c.o.n.c.e.n.t.r.a.t....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-26</th>\n",
       "      <td>rubber drop to two week low after forecast sur...</td>\n",
       "      <td>Rubber declined to a two-week low after a fore...</td>\n",
       "      <td>F.u.t.u.r.e.s. .f.o.r. .d.e.l.i.v.e.r.y. .i.n....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-26</th>\n",
       "      <td>japan credit risk drop to more than two month ...</td>\n",
       "      <td>The cost of insuring corporate bonds from non-...</td>\n",
       "      <td>T.h.e. .M.a.r.k.i.t. .i.T.r.a.x.x. .J.a.p.a.n....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-26</th>\n",
       "      <td>taiwan bond yield fall to three week low a out...</td>\n",
       "      <td>Taiwan ’s 10-year bonds gained, driving the yi...</td>\n",
       "      <td>I.n.d.u.s.t.r.i.a.l. .p.r.o.d.u.c.t.i.o.n. .c....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-26</th>\n",
       "      <td>canada grain export from vancouver see rise to...</td>\n",
       "      <td>Canadian grain shipments from Vancouver, the n...</td>\n",
       "      <td>G.r.a.i.n. .e.x.p.o.r.t.e.d. .t.h.r.o.u.g.h. ....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71966 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        title  \\\n",
       "date                                                            \n",
       "2006-10-20     exxon mobil offer plan to end alaska dispute .   \n",
       "2006-10-23  royal dutch bid for shell canada low sharehold...   \n",
       "2006-10-23  dow end at record high texas instrument off la...   \n",
       "2006-10-23  shell look to buy out canada unit for c xxx bi...   \n",
       "2006-10-23             ford be review all product brand ceo .   \n",
       "...                                                       ...   \n",
       "2013-11-25  statoil to be selective in pick exploration ta...   \n",
       "2013-11-26  rubber drop to two week low after forecast sur...   \n",
       "2013-11-26  japan credit risk drop to more than two month ...   \n",
       "2013-11-26  taiwan bond yield fall to three week low a out...   \n",
       "2013-11-26  canada grain export from vancouver see rise to...   \n",
       "\n",
       "                                                     abstract  \\\n",
       "date                                                            \n",
       "2006-10-20   ANCHORAGE, Alaska  (Reuters) - Exxon Mobil ( ...   \n",
       "2006-10-23   CALGARY, Alberta  (Reuters) - One of Shell Ca...   \n",
       "2006-10-23   NEW YORK  (Reuters) - U.S. stocks rallied on ...   \n",
       "2006-10-23   CALGARY/LONDON  (Reuters) - Royal Dutch Shell...   \n",
       "2006-10-23   DETROIT  (Reuters) - Ford Motor Co. is commit...   \n",
       "...                                                       ...   \n",
       "2013-11-25  Statoil ASA (STL) , Norway’s biggest oil and g...   \n",
       "2013-11-26  Rubber declined to a two-week low after a fore...   \n",
       "2013-11-26  The cost of insuring corporate bonds from non-...   \n",
       "2013-11-26  Taiwan ’s 10-year bonds gained, driving the yi...   \n",
       "2013-11-26  Canadian grain shipments from Vancouver, the n...   \n",
       "\n",
       "                                                      article  \n",
       "date                                                           \n",
       "2006-10-20   . .I.n. .a. .p.r.o.p.o.s.a.l. .s.e.n.t. .e.a....  \n",
       "2006-10-23   .G.a.r.e.y. .A.i.t.k.e.n.,. .a. .p.o.r.t.f.o....  \n",
       "2006-10-23   .S.h.a.r.e.s. .o.f. .W.a.l.-.M.a.r.t. .h.i.t....  \n",
       "2006-10-23   .S.h.e.l.l. .s.a.i.d. .i.n. .a. .s.t.a.t.e.m....  \n",
       "2006-10-23   .T.h.e. .a.u.t.o.m.a.k.e.r. .w.i.l.l. .\".l.o....  \n",
       "...                                                       ...  \n",
       "2013-11-25  S.t.a.t.o.i.l. .w.i.l.l. .c.o.n.c.e.n.t.r.a.t....  \n",
       "2013-11-26  F.u.t.u.r.e.s. .f.o.r. .d.e.l.i.v.e.r.y. .i.n....  \n",
       "2013-11-26  T.h.e. .M.a.r.k.i.t. .i.T.r.a.x.x. .J.a.p.a.n....  \n",
       "2013-11-26  I.n.d.u.s.t.r.i.a.l. .p.r.o.d.u.c.t.i.o.n. .c....  \n",
       "2013-11-26  G.r.a.i.n. .e.x.p.o.r.t.e.d. .t.h.r.o.u.g.h. ....  \n",
       "\n",
       "[71966 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run time for ding: 5166.548908693003\n",
      "processing the vocab cases for title\n",
      "before dropping the words that occurs less than 5 times 23383\n",
      "Dict size 7283\n",
      "Done\n",
      "processing the vocab cases for abstract\n",
      "before dropping the words that occurs less than 5 times 94384\n",
      "Dict size 22926\n",
      "Done\n",
      "processing the vocab cases for article\n",
      "before dropping the words that occurs less than 5 times 482528\n",
      "Dict size 128660\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "##TODO the news start from 2006-10-20 to 2013-11-20 reuters, bloomberg to 2013-11-26\n",
    "train = title['2006-10-20':'2012-06-21']  # from the beginning 2006-10-20 plus 30 days after, just in case\n",
    "validate = title['2012-06-22':'2013-03-11']  # plus 30 days before and after, just in case\n",
    "test = title['2013-03-12':'2013-11-20']  # plus 30 days before and after, just in case\n",
    "stop = timeit.default_timer()\n",
    "print(\"run time for ding:\", stop - start)\n",
    "path = 'newsss/'\n",
    "#os.chdir(path)\n",
    "# os.chdir('/home/jialong/Documents/phrase_embedding/yunke_' + types + '/')\n",
    "train.reset_index().to_csv(\"train.csv\", index=False, encoding='utf-8')\n",
    "validate.reset_index().to_csv(\"validate.csv\", index=False, encoding='utf-8')\n",
    "test.reset_index().to_csv(\"test.csv\", index=False, encoding='utf-8')\n",
    "for i in types:\n",
    "    build_dictionary(title, path, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"start pre-processing the data\")\n",
    "label_one = pd.read_pickle(\"label_one.pickle\")['2006-10-20':'2013-11-21']  # ['2006-11-20':'2013-11-21']\n",
    "path = 'price_set/'\n",
    "length = label_one.shape[0]\n",
    "train = label_one[0:int(length * 0.8)]\n",
    "validate = label_one[int(length * 0.8):int(length * 0.9)]\n",
    "test = label_one[int(length * 0.9):-1]\n",
    "#train.reset_index().to_csv(path + \"train_label.csv\", index=False, encoding='utf-8')  ##2006-10-20 -- 2012-06-21  \n",
    "#validate.reset_index().to_csv(path + \"validate_label.csv\", index=False,              ##2012-06-22 -- 2013-03-11  \n",
    "#                              encoding='utf-8')\n",
    "#test.reset_index().to_csv(path + \"test_label.csv\", index=False, encoding='utf-8')    ##2013-03-12 -- 2013-11-21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
